import asyncio
import json
import os
from typing import Optional, Dict, List, Any
from contextlib import AsyncExitStack

import httpx
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

MODEL = "deepseek/deepseek-v3"
CHUTES_ENDPOINT = "https://chutes.ai/app/chute/154ad01c-a431-5744-83c8-651215124360"

# DeepSeek V3 ëª¨ë¸ìš© íŠ¹ìˆ˜ í† í° ìƒìˆ˜
TOOL_CALLS_BEGIN = "<ï½œtoolâ–callâ–beginï½œ>"
TOOL_CALL_BEGIN = "<ï½œtoolâ–callâ–beginï½œ>"
TOOL_SEP = " "
TOOL_CALL_END = " "
TOOL_CALLS_END = " "
TOOL_OUTPUTS_BEGIN = " "
TOOL_OUTPUT_BEGIN = " "
TOOL_OUTPUT_END = " "
TOOL_OUTPUTS_END = " "
END_OF_SENTENCE = " "
USER = " "
ASSISTANT = " "

MCP_SERVERS = {
    "filesystem": {
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home"],
        "env": None
    },
    "brave_search": {
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-brave-search"],
        "env": {"BRAVE_API_KEY": os.getenv("BRAVE_API_KEY")}
    },
    "github": {
        "command": "npx", 
        "args": ["-y", "@modelcontextprotocol/server-github"],
        "env": {"GITHUB_PERSONAL_ACCESS_TOKEN": os.getenv("GITHUB_TOKEN")}
    },
    "postgres": {
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-postgres"],
        "env": {"DATABASE_URL": os.getenv("DATABASE_URL")}
    }
}

def convert_tool_format(tool):
    """ë„êµ¬ ì •ì˜ë¥¼ OpenAI í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    converted_tool = {
        "type": "function",
        "function": {
            "name": tool.name,
            "description": tool.description,
            "parameters": {
                "type": "object",
                "properties": tool.inputSchema.get("properties", {}),
                "required": tool.inputSchema.get("required", [])
            }
        }
    }
    return converted_tool

def format_deepseek_system_prompt(tools):
    """DeepSeek V3 ëª¨ë¸ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    system_prompt = "You are a helpful assistant with tool calling capabilities. "
    system_prompt += f"When a tool call is needed, you MUST use the following format to issue the call:\n"
    system_prompt += f"{TOOL_CALLS_BEGIN}{TOOL_CALL_BEGIN}function{TOOL_SEP}FUNCTION_NAME\n"
    system_prompt += "```json\n{\"param1\": \"value1\", \"param2\": \"value2\"}\n```"
    system_prompt += f"{TOOL_CALL_END}{TOOL_CALLS_END}\n\n"
    system_prompt += "Make sure the JSON is valid."
    system_prompt += "## Tools\n\n### Function\n\nYou have the following functions available:\n\n"
    
    for tool in tools:
        system_prompt += f"- `{tool['function']['name']}`:\n```json\n{json.dumps(tool, indent=2)}\n```\n"
    
    return system_prompt

def format_deepseek_messages(messages):
    """DeepSeek V3 ëª¨ë¸ìš© ë©”ì‹œì§€ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    formatted_messages = []
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì°¾ê¸°
    system_content = None
    for msg in messages:
        if msg["role"] == "system":
            system_content = msg["content"]
            break
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë©”ì‹œì§€ë¡œ ì¶”ê°€
    if system_content:
        formatted_messages.append({"role": "system", "content": system_content})
    
    # ë‚˜ë¨¸ì§€ ë©”ì‹œì§€ ì¶”ê°€
    for msg in messages:
        if msg["role"] == "system":
            continue  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ì´ë¯¸ ì²˜ë¦¬í•¨
        
        if msg["role"] == "user":
            formatted_content = f"{USER}{msg['content']}{ASSISTANT}"
            formatted_messages.append({"role": "user", "content": formatted_content})
        
        elif msg["role"] == "assistant":
            if "tool_calls" in msg and msg["tool_calls"]:
                # ë„êµ¬ í˜¸ì¶œ ë©”ì‹œì§€ í¬ë§·íŒ…
                content = msg.get("content", "")
                tool_calls_text = TOOL_CALLS_BEGIN
                
                for i, tool_call in enumerate(msg["tool_calls"]):
                    func_name = tool_call["function"]["name"]
                    arguments = tool_call["function"]["arguments"]
                    
                    tool_call_text = f"{TOOL_CALL_BEGIN}function{TOOL_SEP}{func_name}\n"
                    tool_call_text += f"```json\n{arguments}\n```{TOOL_CALL_END}"
                    
                    if i == 0 and content:
                        tool_calls_text += content
                    
                    tool_calls_text += tool_call_text
                
                tool_calls_text += f"{TOOL_CALLS_END}{END_OF_SENTENCE}"
                formatted_messages.append({"role": "assistant", "content": tool_calls_text})
            
            else:
                # ì¼ë°˜ ì‘ë‹µ ë©”ì‹œì§€
                content = msg["content"]
                if content:
                    formatted_messages.append({"role": "assistant", "content": f"{content}{END_OF_SENTENCE}"})
        
        elif msg["role"] == "tool":
            # ë„êµ¬ ì‘ë‹µ ë©”ì‹œì§€
            prefix = "Use the results below to formulate an answer to the user question unless additional information is needed."
            tool_output = f"{TOOL_OUTPUTS_BEGIN}{TOOL_OUTPUT_BEGIN}{msg['content']}{TOOL_OUTPUT_END}"
            formatted_messages.append({"role": "system", "content": f"{prefix} {tool_output}"})
    
    return formatted_messages

async def call_chutes_api(messages, tools=None):
    """Chutes APIë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ tool callingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.getenv('CHUTES_API_KEY')}"
    }
    
    # DeepSeek ëª¨ë¸ìš© ë©”ì‹œì§€ í¬ë§·íŒ…
    if tools:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        system_prompt = format_deepseek_system_prompt(tools)
        has_system = any(msg["role"] == "system" for msg in messages)
        
        if not has_system:
            messages = [{"role": "system", "content": system_prompt}] + messages
        else:
            # ê¸°ì¡´ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
            for i, msg in enumerate(messages):
                if msg["role"] == "system":
                    messages[i]["content"] = system_prompt + "\n\n" + msg["content"]
                    break
    
    # DeepSeek ëª¨ë¸ìš©ìœ¼ë¡œ ë©”ì‹œì§€ ë³€í™˜
    formatted_messages = format_deepseek_messages(messages)
    
    payload = {
        "model": MODEL,
        "messages": formatted_messages,
        "max_tokens": 2000
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{CHUTES_ENDPOINT}/api/v1/chat",
                headers=headers,
                json=payload,
                timeout=60.0
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                return {"error": f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}", "details": response.text}
    except Exception as e:
        return {"error": f"API ìš”ì²­ ì˜¤ë¥˜: {str(e)}"}

class MCPClient:
    def __init__(self):
        self.sessions: Dict[str, ClientSession] = {}
        self.exit_stack = AsyncExitStack()
        self.openai = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY")
        )
        self.messages = []
        self.available_tools = []
        self.use_chutes_api = True

    async def connect_to_servers(self):
        print("MCP ì„œë²„ë“¤ì— ì—°ê²° ì¤‘...")
        
        for server_name, config in MCP_SERVERS.items():
            try:
                print(f"{server_name} ì„œë²„ ì—°ê²° ì‹œë„...")
                server_params = StdioServerParameters(**config)
                stdio_transport = await self.exit_stack.enter_async_context(
                    stdio_client(server_params)
                )
                stdio, write = stdio_transport
                session = await self.exit_stack.enter_async_context(
                    ClientSession(stdio, write)
                )
                
                await session.initialize()
                
                response = await session.list_tools()
                tools = [convert_tool_format(tool) for tool in response.tools]
                
                for tool in tools:
                    tool["function"]["name"] = f"{server_name}_{tool['function']['name']}"
                
                self.sessions[server_name] = session
                self.available_tools.extend(tools)
                
                print(f"âœ“ {server_name} ì„œë²„ ì—°ê²° ì™„ë£Œ - ë„êµ¬ {len(tools)}ê°œ ë“±ë¡")
                
            except Exception as e:
                print(f"âœ— {server_name} ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
                continue

        print(f"\nì´ {len(self.available_tools)}ê°œì˜ ë„êµ¬ê°€ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    async def execute_tool_call(self, tool_name: str, tool_args: Dict[str, Any]) -> str:
        server_name = tool_name.split('_')[0]
        actual_tool_name = '_'.join(tool_name.split('_')[1:])
        
        if server_name not in self.sessions:
            return f"ì„œë²„ '{server_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            session = self.sessions[server_name]
            result = await session.call_tool(actual_tool_name, tool_args)
            return str(result.content) if hasattr(result, 'content') else str(result)
        except Exception as e:
            return f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}"

    async def parse_deepseek_response(self, response_content):
        """DeepSeek ëª¨ë¸ì˜ ì‘ë‹µì—ì„œ ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        if TOOL_CALLS_BEGIN not in response_content:
            return None
            
        try:
            # ë„êµ¬ í˜¸ì¶œ ë¶€ë¶„ ì¶”ì¶œ
            tool_calls_text = response_content.split(TOOL_CALLS_BEGIN)[1].split(TOOL_CALLS_END)[0]
            tool_calls = []
            
            # ê° ë„êµ¬ í˜¸ì¶œ íŒŒì‹±
            for tool_call_text in tool_calls_text.split(TOOL_CALL_BEGIN)[1:]:
                if TOOL_CALL_END not in tool_call_text:
                    continue
                    
                parts = tool_call_text.split(TOOL_SEP)
                if len(parts) < 2:
                    continue
                    
                tool_type = parts[0].strip()
                remaining = parts[1].split(TOOL_CALL_END)[0]
                
                # í•¨ìˆ˜ ì´ë¦„ê³¼ ì¸ì ì¶”ì¶œ
                func_name_parts = remaining.split("\n```json", 1)
                if len(func_name_parts) < 2:
                    continue
                    
                func_name = func_name_parts[0].strip()
                arguments = func_name_parts[1].strip().rstrip("```").strip()
                
                tool_calls.append({
                    "type": tool_type,
                    "function": {
                        "name": func_name,
                        "arguments": arguments
                    },
                    "id": f"call_{len(tool_calls)}"
                })
            
            return tool_calls
        except Exception as e:
            print(f"ë„êµ¬ í˜¸ì¶œ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None

    async def process_query(self, query: str) -> str:
        self.messages.append({
            "role": "user", 
            "content": query
        })

        try:
            if self.use_chutes_api:
                # Chutes APIë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ë„êµ¬ í˜¸ì¶œ ìˆ˜í–‰
                response_data = await call_chutes_api(self.messages, self.available_tools)
                
                if "error" in response_data:
                    return f"Chutes API ì˜¤ë¥˜: {response_data['error']}"
                
                assistant_message = response_data["choices"][0]["message"]
                response_content = assistant_message["content"]
                
                # DeepSeek íŠ¹ìˆ˜ í¬ë§·ì—ì„œ ë„êµ¬ í˜¸ì¶œ íŒŒì‹±
                tool_calls = await self.parse_deepseek_response(response_content)
                
                if tool_calls:
                    # ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                    assistant_message_with_tools = {
                        "role": "assistant",
                        "content": response_content.split(TOOL_CALLS_BEGIN)[0].strip(),
                        "tool_calls": tool_calls
                    }
                    self.messages.append(assistant_message_with_tools)
                    
                    # ê° ë„êµ¬ í˜¸ì¶œ ì‹¤í–‰
                    for tool_call in tool_calls:
                        tool_name = tool_call["function"]["name"]
                        tool_args = json.loads(tool_call["function"]["arguments"]) if tool_call["function"]["arguments"] else {}
                        
                        print(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {tool_name}")
                        result = await self.execute_tool_call(tool_name, tool_args)
                        
                        self.messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call["id"],
                            "name": tool_name,
                            "content": result
                        })
                    
                    # í›„ì† ì‘ë‹µì„ ìœ„í•´ Chutes API ë‹¤ì‹œ í˜¸ì¶œ
                    follow_up_data = await call_chutes_api(self.messages)
                    
                    if "error" in follow_up_data:
                        return f"Chutes API í›„ì† í˜¸ì¶œ ì˜¤ë¥˜: {follow_up_data['error']}"
                    
                    follow_up_content = follow_up_data["choices"][0]["message"]["content"]
                    # íŠ¹ìˆ˜ í† í° ì œê±°
                    final_content = follow_up_content.replace(END_OF_SENTENCE, "")
                    
                    # ë§ˆì§€ë§‰ ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
                    self.messages.append({
                        "role": "assistant",
                        "content": final_content
                    })
                    
                    return final_content
                else:
                    # ë„êµ¬ í˜¸ì¶œ ì—†ëŠ” ì¼ë°˜ ì‘ë‹µ
                    clean_content = response_content.replace(END_OF_SENTENCE, "")
                    self.messages.append({
                        "role": "assistant", 
                        "content": clean_content
                    })
                    return clean_content
            else:
                # OpenRouter API ì‚¬ìš©
                response = self.openai.chat.completions.create(
                    model=MODEL,
                    tools=self.available_tools,
                    messages=self.messages,
                    max_tokens=2000
                )
                
                message = response.choices[0].message
                self.messages.append(message.model_dump())
                
                if message.tool_calls:
                    for tool_call in message.tool_calls:
                        tool_name = tool_call.function.name
                        tool_args = json.loads(tool_call.function.arguments) if tool_call.function.arguments else {}
                        
                        print(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {tool_name}")
                        result = await self.execute_tool_call(tool_name, tool_args)
                        
                        self.messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "name": tool_name,
                            "content": result
                        })
                    
                    follow_up_response = self.openai.chat.completions.create(
                        model=MODEL,
                        messages=self.messages,
                        max_tokens=2000
                    )
                    
                    return follow_up_response.choices[0].message.content
                else:
                    return message.content
            
        except Exception as e:
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    async def chat_loop(self):
        print("\nğŸ¤– DeepSeek-V3 MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ 'quit'ë¥¼ ì…ë ¥í•˜ì—¬ ì¢…ë£Œí•˜ì„¸ìš”.")
        print("ì‚¬ìš© API:", "Chutes API" if self.use_chutes_api else "OpenRouter API")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë²„:", list(self.sessions.keys()))
        
        while True:
            try:
                query = input("\nğŸ’¬ ì§ˆë¬¸: ").strip()
                
                if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                    
                if query.lower() == 'switch':
                    self.use_chutes_api = not self.use_chutes_api
                    print(f"API ë³€ê²½ë¨: {'Chutes API' if self.use_chutes_api else 'OpenRouter API'}")
                    continue
                
                if not query:
                    continue
                
                print("ğŸ¤” ì²˜ë¦¬ ì¤‘...")
                result = await self.process_query(query)
                print("\nğŸ“ ì‘ë‹µ:")
                print(result)
                
            except KeyboardInterrupt:
                print("\n\ní´ë¼ì´ì–¸íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"ì˜¤ë¥˜: {e}")

    async def cleanup(self):
        await self.exit_stack.aclose()

async def main():
    client = MCPClient()
    try:
        await client.connect_to_servers()
        if client.sessions:
            await client.chat_loop()
        else:
            print("ì—°ê²°ëœ MCP ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    finally:
        await client.cleanup()

if __name__ == "__main__":
    asyncio.run(main()) 