from openai import OpenAI
import os
from dotenv import load_dotenv
import json
import requests
import time
from bs4 import BeautifulSoup
import re
from rich.console import Console
from rich.markdown import Markdown
from rich.live import Live

# Rich Console ì´ˆê¸°í™”
console = Console()

def clean_text(text):
    cleaned_text = re.sub(r'\s+', ' ', text)
    cleaned_text = cleaned_text.strip()
    return cleaned_text

def enhanced_search(query: str):
    global last_search_context
    
    # ê²€ìƒ‰ì–´ ì •ë³´ ì—…ë°ì´íŠ¸
    last_search_context["query"] = query
    if "ì—”ë¯¹ìŠ¤" in query or "NMIXX" in query:
        last_search_context["topic"] = "ì—”ë¯¹ìŠ¤"
    elif "í…ŒìŠ¬ë¼" in query:
        last_search_context["topic"] = "í…ŒìŠ¬ë¼"
    
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    response = requests.get(f"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query={query}")

    if response.status_code == 200:
        soup = BeautifulSoup(response.content, 'lxml')
        main_pack = soup.find(id='main_pack')
        
        if main_pack:
            text_only = main_pack.get_text(separator='\n').strip()
            cleaned_text = clean_text(text_only)
            
            if len(cleaned_text) > 1500:
                cleaned_text = cleaned_text[:1500] + "..."
            
            return cleaned_text
        else:
            return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    else:
        return f"ê²€ìƒ‰ ìš”ì²­ ì‹¤íŒ¨. ìƒíƒœ ì½”ë“œ: {response.status_code}"

def routing(agent: str):
    return agent

TOOL_MAPPING = {
    "search": enhanced_search,
    "routing": routing,
}

TOOLS = [{
    "type": "function",
    "function": {
        "name": "search",
        "description": "Search the web for a given query.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "The query to search for."
                }
            },
            "required": ["query"],
            "additionalProperties": False
        },
        "strict": True
    }
}]

ROUTING = [{
    "type": "function",
    "function": {
        "name": "routing",
        "description": "Route the user's request to the appropriate agent.",
        "parameters": {
            "type": "object",
            "properties": {
                "agent": {
                    "type": "string",
                    "enum": ["chat", "tool"],
                    "description": "The agent to route the user's request to.",
                }
            },
            "required": ["agent"],
            "additionalProperties": False,
        },
        "strict": True
    }
}]

# ì „ì—­ ë³€ìˆ˜ë¡œ ë§ˆì§€ë§‰ ê²€ìƒ‰ì–´ ì¶”ì 
last_search_context = {"query": None, "topic": None}

class AIAgent:
    def __init__(self, model: str = None, tools=None, endpoint: str = "https://openrouter.ai/api/v1", system_prompt: str = None, is_chat_agent: bool = False, **kwargs):
        load_dotenv()
        self.model = model
        self.system_prompt = system_prompt
        self.tools = tools
        self.is_chat_agent = is_chat_agent
        self.client = OpenAI(base_url=endpoint, api_key=os.getenv("OPENROUTER_API_KEY"))
        self.base_history = [{"role": "system", "content": system_prompt}]
        self.history = self.base_history.copy()
        self.last_search_query = None
        
    def text_response(self, user_prompt, context_info=None):
        if context_info:
            enhanced_prompt = f"{user_prompt}\n\nì»¨í…ìŠ¤íŠ¸ ì •ë³´: {context_info}"
        else:
            enhanced_prompt = user_prompt
            
        self.history.append({"role": "user", "content": enhanced_prompt})
        
        if len(self.history) > 10:
            self.history = [self.history[0]] + self.history[-8:]
        
        params = {
            "model": self.model,
            "messages": self.history,
            "stream": True,
        }
        
        if self.tools:
            params["tools"] = self.tools
            params["tool_choice"] = "auto"
        
        response = self.client.chat.completions.create(**params)
        
        final_response = ""
        function_name = ""
        function_args = ""
        json_buffer = ""
        
        # chat_agentì¸ ê²½ìš° Live ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©
        if self.is_chat_agent:
            with Live(Markdown(""), refresh_per_second=10, console=console) as live:
                for chunk in response:
                    delta = chunk.choices[0].delta
                    
                    if delta.content:
                        final_response += delta.content
                        # ì‹¤ì‹œê°„ìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ ì—…ë°ì´íŠ¸
                        live.update(Markdown(final_response))
                        
        else:
            # ì¼ë°˜ ì—ì´ì „íŠ¸ëŠ” ê¸°ì¡´ ë°©ì‹ ìœ ì§€
            for chunk in response:
                delta = chunk.choices[0].delta
                
                if delta.content:
                    print(delta.content, end="", flush=True)
                    final_response += delta.content
                    
                elif delta.tool_calls:
                    tool_call = delta.tool_calls[0]
                    
                    if tool_call.function.name:
                        function_name += tool_call.function.name
                        print(f"\nAction: {tool_call.function.name}", end="", flush=True)
                        
                    if tool_call.function.arguments:
                        json_buffer += tool_call.function.arguments
                        print(tool_call.function.arguments, end="", flush=True)
                        
                        if json_buffer.count('{') == json_buffer.count('}') and json_buffer.count('{') > 0:
                            function_args = json_buffer
                            json_buffer = ""
        
        if final_response:
            self.history.append({"role": "assistant", "content": final_response})
            return final_response
        elif function_name:
            return (function_name, function_args)
        else:
            return ""

    def get_tool_response(self, *args):
        if len(args) != 2:
            return "ë„êµ¬ í˜¸ì¶œ ì˜¤ë¥˜"
            
        tool_name = args[0]
        raw_args = args[1]
        
        # JSON ìœ íš¨ì„± ê²€ì‚¬ ê°•í™”
        try:
            tool_args = json.loads(raw_args)
        except json.JSONDecodeError:
            # ë§ˆì§€ë§‰ ì¤‘ê´„í˜¸ ì°¾ì•„ì„œ ì˜ë¼ë‚´ê¸° ì‹œë„
            last_brace = raw_args.rfind('}')
            if last_brace != -1:
                try:
                    tool_args = json.loads(raw_args[:last_brace+1])
                except:
                    # ì •ê·œì‹ìœ¼ë¡œ query ê°’ ì¶”ì¶œ
                    match = re.search(r'"query":\s*"([^"]*)"', raw_args)
                    if match:
                        tool_args = {"query": match.group(1)}
                    else:
                        tool_args = {"query": raw_args}
            else:
                tool_args = {"query": raw_args}
        
        # ê²€ìƒ‰ì–´ ì €ì¥
        if tool_name == "search":
            self.last_search_query = tool_args.get("query")

        tool_result = TOOL_MAPPING[tool_name](**tool_args)
        
        print(f"\nObservation: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.")
        print(f"Thought: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.")
        print(f"Final Answer: ")
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.history.append({
            "role": "assistant", 
            "content": f"ê²€ìƒ‰ ê²°ê³¼: {tool_result[:500]}..."
        })
        
        return tool_result

if __name__ == "__main__":
    route_agent = AIAgent(
        model="openai/gpt-4.1-mini",
        tools=ROUTING,
        system_prompt="""ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{"agent":"chat"} ë˜ëŠ” {"agent":"tool"}

í˜„ì¬ ì •ë³´ë‚˜ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° "tool"ì„, ì¼ë°˜ì ì¸ ëŒ€í™”ëŠ” "chat"ì„ ì„ íƒí•˜ì„¸ìš”."""
    )

    chat_agent = AIAgent(
        model="deepseek/deepseek-chat-v3-0324:free",
        tools=None,
        is_chat_agent=True,  # ì‹¤ì‹œê°„ ë§ˆí¬ë‹¤ìš´ ë Œë”ë§ í™œì„±í™”
        endpoint="https://openrouter.ai/api/v1",
        system_prompt=f"""ë‹¹ì‹ ì€ ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ë‹µë³€ì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:

- **êµµì€ ê¸€ì”¨**ë¡œ ì¤‘ìš”í•œ ì •ë³´ ê°•ì¡°
- `ë°±í‹±`ìœ¼ë¡œ íŠ¹ì • ìš©ì–´ë‚˜ ìˆ«ì í‘œì‹œ
- ## ì œëª©ìœ¼ë¡œ ì„¹ì…˜ êµ¬ë¶„
- ğŸ“… ğŸ‚ ğŸ’¡ ğŸ” ë“± ì´ëª¨ì§€ í™œìš©
- > ì¸ìš©ë¬¸ìœ¼ë¡œ ë¶€ê°€ ì„¤ëª…
- ëª©ë¡ì€ - ë˜ëŠ” 1. ì‚¬ìš©

í˜„ì¬ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}

ì˜ˆì‹œ:
## ğŸ‚ ìƒì¼ ì •ë³´
**ì¥ê·œì§„**ì˜ ìƒì¼ì€ `2006ë…„ 5ì›” 26ì¼`ì…ë‹ˆë‹¤.

> ğŸ’¡ **ì°¸ê³ **: í˜„ì¬ ë§Œ 19ì„¸ì…ë‹ˆë‹¤."""
    )
    
    tool_agent = AIAgent(
        model="openai/gpt-4.1-mini",
        tools=TOOLS, 
        endpoint="https://openrouter.ai/api/v1",
        system_prompt=f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

ê²€ìƒ‰ì–´ ìƒì„± ê·œì¹™:
1. ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ë¥¼ ì œê³µí•˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
2. "ë‹¤ì‹œ ì•Œì•„ë´ì¤˜", "ì¬ê²€ìƒ‰í•´ì¤˜" ë“±ì˜ ìš”ì²­ì´ë©´ ì´ì „ ê²€ìƒ‰ ì£¼ì œë¥¼ ì°¸ê³ í•˜ì—¬ ê²€ìƒ‰ì–´ ìƒì„±
3. ì• ë§¤í•œ ìš”ì²­ì´ë©´ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ì§ˆë¬¸
4. ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° í˜„ì¬ ì‹œê°„ì„ ì°¸ê³ í•˜ì—¬ ê²€ìƒ‰ì–´ ìƒì„±

ì˜ˆì‹œ:
- "ê·œì§„ì´ ìƒì¼ ëª‡ì¼ ë‚¨ì•˜ì§€?" â†’ "ì—”ë¯¹ìŠ¤ ì¥ê·œì§„ ìƒì¼ ë‚¨ì€ ì¼ìˆ˜"
- "í…ŒìŠ¬ë¼ ì£¼ê°€ ì–¼ë§ˆì•¼?" â†’ "í…ŒìŠ¬ë¼ ì‹¤ì‹œê°„ ì£¼ê°€"

í˜„ì¬ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}"""
    )
    
    while True:
        try:
            user_prompt = input("\nYou: ")
            
            if user_prompt == "exit":
                break   
            
            print(f"\nğŸ¯ ì‚¬ìš©ì ìš”ì²­: {user_prompt}")
            
            # ë¼ìš°íŒ… ê²°ì •
            route_result = route_agent.text_response(user_prompt)
            
            if isinstance(route_result, tuple):
                route = route_agent.get_tool_response(*route_result)
            else:
                route = route_result
            
            print(f"\n[ë¼ìš°íŒ…: {route}]\n")
            
            if "chat" in route:
                chat_agent.text_response(user_prompt)
            elif "tool" in route:
                # ì´ì „ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì œê³µ
                context_info = f"ì´ì „ ê²€ìƒ‰ ì£¼ì œ: {last_search_context.get('topic', 'ì—†ìŒ')}, ë§ˆì§€ë§‰ ê²€ìƒ‰ì–´: {last_search_context.get('query', 'ì—†ìŒ')}"
                
                tool_result = tool_agent.text_response(user_prompt, context_info=context_info)
                if isinstance(tool_result, tuple):
                    search_result = tool_agent.get_tool_response(*tool_result)
                    
                    summary = search_result[:800] if len(search_result) > 800 else search_result
                    final_response = chat_agent.text_response(
                        f"""ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

ê²€ìƒ‰ ê²°ê³¼: {summary}

ì‚¬ìš©ì ì§ˆë¬¸: {user_prompt}

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:
- ì œëª©ì€ ## ì‚¬ìš©
- ì¤‘ìš” ì •ë³´ëŠ” **êµµê²Œ**
- ë‚ ì§œ/ìˆ«ìëŠ” `ë°±í‹±`ìœ¼ë¡œ ê°ì‹¸ê¸°
- ì´ëª¨ì§€ í™œìš©í•˜ì—¬ ì‹œê°ì  íš¨ê³¼
- > ì¸ìš©ë¬¸ìœ¼ë¡œ ë¶€ê°€ ì„¤ëª…"""
                    )
                    
        except KeyboardInterrupt:
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            continue
